{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu2RLiyQTbsj",
        "outputId": "c4d71636-b30f-490d-f88e-a981cbd8aa71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Define a simple dataset class\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, texts, labels, word_to_idx):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.word_to_idx = word_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = [self.word_to_idx[word] for word in self.texts[idx].split()]\n",
        "\n",
        "        try:\n",
        "            label = torch.as_tensor(int(self.labels[idx])).clone().detach()\n",
        "        except ValueError:\n",
        "            label = torch.as_tensor(0)\n",
        "\n",
        "        return {'text': torch.LongTensor(text), 'label': label}\n",
        "\n",
        "def collate_batch(batch):\n",
        "    texts = [item['text'] for item in batch]\n",
        "    labels = [item['label'] for item in batch]\n",
        "\n",
        "    padded_texts = pad_sequence(texts, batch_first=True, padding_value=0)\n",
        "\n",
        "    return {'text': padded_texts, 'label': torch.stack(labels)}\n",
        "\n",
        "def read_data_from_csv(file_path):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        next(file)\n",
        "        for line in file:\n",
        "            parts = line.strip().split(',')\n",
        "            if len(parts) >= 2:\n",
        "                texts.append(parts[0])\n",
        "                labels.append(parts[1].strip('\\\"'))\n",
        "    return texts, labels\n",
        "\n",
        "# Improved Emotion Analysis Model\n",
        "class ImprovedEmotionAnalysisModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pretrained_embeddings=None):\n",
        "        super(ImprovedEmotionAnalysisModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        if pretrained_embeddings is not None:\n",
        "            self.embedding.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
        "            self.embedding.weight.requires_grad = False\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        lstm_out = lstm_out[:, -1, :]\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        out = self.fc(lstm_out)\n",
        "        return out\n",
        "\n",
        "# Read data from CSV file\n",
        "file_path = '/content/gdrive/MyDrive/DS677 - Fall 23 - DL Project - Paresh, Ojaswi, Dinesh/TextAndEmotions.csv'\n",
        "texts, labels = read_data_from_csv(file_path)\n",
        "\n",
        "# Create vocabulary and word_to_idx mapping\n",
        "vocab = set(' '.join(texts).split())\n",
        "word_to_idx = {word: idx + 1 for idx, word in enumerate(vocab)}\n",
        "\n",
        "# Update the dataset and pad sequences\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = EmotionDataset(train_texts, train_labels, word_to_idx)\n",
        "test_dataset = EmotionDataset(test_texts, test_labels, word_to_idx)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "# Model parameters\n",
        "embedding_dim = 50\n",
        "hidden_dim = 100\n",
        "output_dim = len(set(labels))\n",
        "\n",
        "# Initialize the model and choose the appropriate pre-trained embeddings\n",
        "# Download GloVe embeddings from https://nlp.stanford.edu/projects/glove/ and adjust the path\n",
        "# Example code to load GloVe embeddings:\n",
        "# embeddings_index = {}\n",
        "# with open('path_to_glove/glove.6B.50d.txt', 'r', encoding='utf-8') as f:\n",
        "#     for line in f:\n",
        "#         values = line.split()\n",
        "#         word = values[0]\n",
        "#         coefs = np.asarray(values[1:], dtype='float32')\n",
        "#         embeddings_index[word] = coefs\n",
        "# embedding_matrix = np.zeros((len(word_to_idx) + 1, embedding_dim))\n",
        "# for word, i in word_to_idx.items():\n",
        "#     embedding_vector = embeddings_index.get(word)\n",
        "#     if embedding_vector is not None:\n",
        "#         embedding_matrix[i] = embedding_vector\n",
        "# model = ImprovedEmotionAnalysisModel(\n",
        "#     vocab_size=len(word_to_idx) + 1,\n",
        "#     embedding_dim=embedding_dim,\n",
        "#     hidden_dim=hidden_dim,\n",
        "#     output_dim=output_dim,\n",
        "#     pretrained_embeddings=embedding_matrix,\n",
        "# ).to(device)\n",
        "\n",
        "model = ImprovedEmotionAnalysisModel(\n",
        "    vocab_size=len(word_to_idx) + 1,\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_dim=hidden_dim,\n",
        "    output_dim=output_dim,\n",
        ").to(device)\n",
        "\n",
        "# Training parameters\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "epochs = 50\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}', leave=False):\n",
        "        text, label = batch['text'].to(device), batch['label'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(text)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        # Implement gradient clipping to prevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader)}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc='Evaluating', leave=False):\n",
        "        text, label = batch['text'].to(device), batch['label'].to(device)\n",
        "        output = model(text)\n",
        "        predictions = torch.argmax(output, dim=1)\n",
        "        all_predictions.extend(predictions.cpu().numpy())\n",
        "        all_labels.extend(label.cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_predictions)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUNL-E2hTcXE",
        "outputId": "580be36a-6fd6-4610-acaa-9cee97b6c03b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 4.298942142062717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50, Loss: 2.4066073894500732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/50, Loss: 0.8778071800867716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/50, Loss: 0.5014093981848823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50, Loss: 0.4190385606553819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/50, Loss: 0.4098073012299008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/50, Loss: 0.39207568764686584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/50, Loss: 0.4053659869564904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/50, Loss: 0.38669821951124406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50, Loss: 0.38769100109736127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/50, Loss: 0.39474110470877755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/50, Loss: 0.39178109500143266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/50, Loss: 0.3780011369122399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/50, Loss: 0.384607646200392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/50, Loss: 0.34878357582622105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/50, Loss: 0.33234446081850266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/50, Loss: 0.3111840420299106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/50, Loss: 0.2962263855669234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/50, Loss: 0.2789573238955604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/50, Loss: 0.23815032177501255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/50, Loss: 0.21328215135468376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/50, Loss: 0.1740485429763794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/50, Loss: 0.15266337659623888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/50, Loss: 0.13207165648539862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/50, Loss: 0.11312453986869918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/50, Loss: 0.11571580585506228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/50, Loss: 0.09975932165980339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/50, Loss: 0.09674576297402382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/50, Loss: 0.08749340826438533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/50, Loss: 0.08410173861516847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/50, Loss: 0.08670817501842976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/50, Loss: 0.07847022472156419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/50, Loss: 0.07839789179464181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/50, Loss: 0.08933944130937259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/50, Loss: 0.07552709989249706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/50, Loss: 0.0832259746061431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/50, Loss: 0.08482471501661672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/50, Loss: 0.077828049659729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/50, Loss: 0.08589657851391369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/50, Loss: 0.06929195848190123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/50, Loss: 0.07019840718971358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/50, Loss: 0.07724801844192876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/50, Loss: 0.04984689628084501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/50, Loss: 0.04687118778626124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/50, Loss: 0.03701224115987619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/50, Loss: 0.02200316648102469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/50, Loss: 0.02892321317146222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/50, Loss: 0.025212829052988026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/50, Loss: 0.02620111669724186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/50, Loss: 0.029320076832340822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 93.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample inputs\n",
        "sample_inputs = [\n",
        "    \"I love the new feature!\",\n",
        "    \"I am satisfied with the customer service.\",\n",
        "    \"This movie is not good!\",\n",
        "    \"This software have lots of features.\",\n",
        "    \"Incredible customer experience!\",\n",
        "    \"I am anxious\"\n",
        "]\n",
        "\n",
        "# Predict emotions for each sample input\n",
        "for sample_input in sample_inputs:\n",
        "    # Preprocess the sample input\n",
        "    sample_input_indices = [word_to_idx[word] for word in sample_input.split() if word in word_to_idx]\n",
        "\n",
        "    # Check if the sample input is empty after filtering\n",
        "    if not sample_input_indices:\n",
        "        print(f\"No valid words found in the sample input: {sample_input}\")\n",
        "    else:\n",
        "        # Convert to tensor and add batch dimension\n",
        "        sample_input_tensor = torch.LongTensor(sample_input_indices).unsqueeze(0).to(device)\n",
        "\n",
        "        # Pass through the trained model\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            output = model(sample_input_tensor)\n",
        "\n",
        "        # Interpret the model's output\n",
        "        predicted_class = torch.argmax(output, dim=1).item()\n",
        "\n",
        "        # Map the predicted class to the corresponding emotion label\n",
        "        emotion_labels = {0: \"Negative\", 1: \"Positive\"}  # Update with your specific labels\n",
        "        predicted_emotion = emotion_labels.get(predicted_class, \"Unknown\")\n",
        "\n",
        "        print(f\"The predicted emotion for the sample input '{sample_input}' is: {predicted_emotion}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo0AZ3cVDVKg",
        "outputId": "4e142387-f93e-4d20-b0f9-c7476feefe03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted emotion for the sample input 'I love the new feature!' is: Positive\n",
            "The predicted emotion for the sample input 'I am satisfied with the customer service.' is: Positive\n",
            "The predicted emotion for the sample input 'This movie is not good!' is: Positive\n",
            "The predicted emotion for the sample input 'This software have lots of features.' is: Negative\n",
            "The predicted emotion for the sample input 'Incredible customer experience!' is: Positive\n",
            "The predicted emotion for the sample input 'I am anxious' is: Negative\n"
          ]
        }
      ]
    }
  ]
}